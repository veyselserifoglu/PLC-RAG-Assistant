{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6009debe",
   "metadata": {},
   "source": [
    "# LLM Response Quality Comparison (Simulated RAG)\n",
    "\n",
    "**Objective:** To evaluate which locally runnable, quantized LLM provides the most accurate, coherent, and helpful answers when given PLC-related questions and relevant context (simulating RAG retrieval).\n",
    "\n",
    "**Methodology:**\n",
    "1.  **Prepare Test Cases:** Create pairs of (PLC query, manually selected relevant context chunks).\n",
    "2.  **Select LLMs:** Choose a few candidate quantized LLMs accessible via Ollama.\n",
    "3.  **Generate Responses:** For each LLM and test case, construct a prompt and generate a response.\n",
    "4.  **Qualitative Evaluation:** Manually score responses based on accuracy, relevance, faithfulness, clarity, and helpfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "\n",
    "def get_llm_test_cases():\n",
    "    \"\"\"\n",
    "    Returns a list of dictionaries, each containing a query and relevant context.\n",
    "    Replace this with your actual test cases.\n",
    "    Context should be what you expect a good retriever to find.\n",
    "    \"\"\"\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"query\": \"How do I declare a global variable in CODESYS Structured Text that can be accessed by multiple POUs?\",\n",
    "            \"context\": [\n",
    "                \"Global variables in CODESYS are typically declared in a Global Variable List (GVL).\",\n",
    "                \"To declare a variable in a GVL, you use the VAR_GLOBAL keyword. Example: VAR_GLOBAL MyGlobalCounter : INT; END_VAR\",\n",
    "                \"POUs can then access this variable directly by its name, provided the GVL is part of the project.\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"What is the purpose of the TON timer in PLC programming?\",\n",
    "            \"context\": [\n",
    "                \"The TON (Timer On-Delay) function block is used to create a time delay before an output is set to TRUE.\",\n",
    "                \"When the input IN of the TON block becomes TRUE, the timer starts counting up to the preset time (PT).\",\n",
    "                \"Once the elapsed time (ET) reaches the preset time (PT), the output Q becomes TRUE and remains TRUE as long as IN is TRUE.\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Explain the difference between a Function and a Function Block in CODESYS.\",\n",
    "            \"context\": [\n",
    "                \"Functions (FCs) in CODESYS are POUs that execute and return a value. They do not have memory of their own between calls (stateless).\",\n",
    "                \"Function Blocks (FBs) are POUs that have their own instance memory. This means they can retain their state between calls.\",\n",
    "                \"Typically, FBs are used for operations that require internal state, like timers, counters, or state machines, while Functions are for reusable calculations.\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    return test_cases\n",
    "\n",
    "llm_test_cases = get_llm_test_cases()\n",
    "print(f\"Loaded {len(llm_test_cases)} LLM test cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980cd436",
   "metadata": {},
   "source": [
    "## 2. Define LLMs to Compare (from Ollama)\n",
    "List the Ollama model names you want to test (ensure they are pulled locally: `ollama pull <model_name>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a495f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model_names = [\n",
    "    \"llama3:8b-instruct-q4_K_M\",\n",
    "    \"mistral:7b-instruct-v0.2-q4_K_M\",\n",
    "]\n",
    "\n",
    "local_models = ollama.list()['models']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e67b9",
   "metadata": {},
   "source": [
    "## 3. Generate Responses from LLMs\n",
    "\n",
    "For each LLM and each test case:\n",
    "- Construct a prompt using the query and the provided context.\n",
    "- Generate a response from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_response(model_name, query, context_chunks):\n",
    "    context_str = \"\\n\".join(context_chunks)\n",
    "    prompt = f\"Given the following information:\\n---\\n{context_str}\\n---\\nAnswer the question: {query}\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': prompt,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return response[\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response from {model_name}: {e}\")\n",
    "        return \"Error: Could not generate response.\"\n",
    "\n",
    "llm_results = []\n",
    "\n",
    "for test_case in llm_test_cases:\n",
    "    query = test_case[\"query\"]\n",
    "    context = test_case[\"context\"]\n",
    "    \n",
    "    case_results = {\"query\": query, \"context\": \"\\n\".join(context), \"responses\": {}}\n",
    "    print(f\"\\n--- Processing Query: {query[:80]}... ---\")\n",
    "    \n",
    "    for model_name in ollama_model_names:\n",
    "        print(f\"  Generating response from {model_name}...\")\n",
    "        response_text = generate_llm_response(model_name, query, context)\n",
    "        case_results[\"responses\"][model_name] = response_text\n",
    "        print(f\"    {model_name} Response: {response_text[:150]}...\") # Print a snippet\n",
    "        \n",
    "    llm_results.append(case_results)\n",
    "\n",
    "# df_llm_results = pd.DataFrame(llm_results)\n",
    "# print(df_llm_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083935f",
   "metadata": {},
   "source": [
    "## 4. Qualitative Evaluation of LLM Responses\n",
    "\n",
    "Review the `llm_results`. For each query and each LLM, evaluate the generated response based on the following criteria:\n",
    "\n",
    "*   **Accuracy:** Is the answer factually correct based on the provided context?\n",
    "*   **Relevance:** Does it directly answer the question?\n",
    "*   **Faithfulness:** Does it stick to the provided context, or does it introduce outside information/hallucinate?\n",
    "*   **Clarity & Conciseness:** Is the answer easy to understand and to the point?\n",
    "*   **Helpfulness:** Would this answer be genuinely useful to a student trying to solve a PLC programming problem?\n",
    "\n",
    "Assign scores (e.g., on a 1-5 scale) for each criterion to help in comparing the models. This will guide your choice of LLM for the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4894236",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in llm_results:\n",
    "    print(f\"\\n{'='*20} QUERY: {item['query']} {'='*20}\")\n",
    "    print(f\"\\nCONTEXT PROVIDED:\\n{item['context']}\")\n",
    "    for model_name, response in item['responses'].items():\n",
    "        print(f\"\\n--- Response from {model_name} ---\")\n",
    "        print(response)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "\n",
    "print(\"\\nReview complete. Consider creating a spreadsheet or structured document for formal scoring.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
